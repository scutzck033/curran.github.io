---
title: DL实战常用代码速查
categories: 
- python
tags: 
- DL编程
updated: 2018-05-28
---
**这里记录一些自己常用的DL编程用法，包括前期的数据处理数据分析到后期的模型训练以及实验结果分析，以便自己快速开发。**

# 数据处理
## 处理数据标签(lable)
### 将数值标签进行独热(one-hot)编码
```
from keras.utils import np_utils
one_hot_y = np_utils.to_categorical(y)
```
### 将分类器预测的标签概率分布转化为预测标签
```
import numpy as np
predict_lables = np.argmax(model.predict(test_X),axis=1)
```
## 使用sklearn划分训练集和测试集
```
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.5)
```
## 使用sklearn进行特征标准化/归一化
### 特征标准化(z-score)
标准化的公式为：(X-mean)/std  计算时对每个属性/每列分别进行。  

将数据按期属性（按列进行）减去其均值，并处以其方差。得到的结果是，对于每个属性/每列来说所有数据都聚集在0附近，方差为1。  

使用sklearn.preprocessing.scale()函数，可以直接将给定数据进行标准化。
```
from sklearn import preprocessing
X_scaled = preprocessing.scale(X)
```
### 特征归一化
除了标准化外，另一种常用的方法是将属性缩放到一个指定的最大和最小值（通常是0-1）之间，这可以通过preprocessing.MinMaxScaler类实现。

使用这种方法的目的包括：

1、对于方差非常小的属性可以增强其稳定性。

2、维持稀疏矩阵中为0的条目。
```
from sklearn import preprocessing
min_max_scaler = preprocessing.MinMaxScaler()
X_train_minmax = min_max_scaler.fit_transform(X_train)
```

# 数据可视化
数据可视化推荐一个工具: [yellowbrick](http://www.scikit-yb.org/en/latest/api/index.html)

# 模型训练
当数据量较大时，可以考虑用fit_generator()函数，减少数据对显存的占用。  
fit_generator的输入参数需要是generator,图像数据的话，可以用ImageDataGenerator：
```
from keras.preprocessing.image import ImageDataGenerator
        
train_datagen = ImageDataGenerator()
train_generator = train_datagen.flow(x=trainX, y=trainY, batch_size=batch_size）
test_datagen = ImageDataGenerator()
test_generator = test_datagen.flow(x=testX, y=testY, batch_size=batch_size)

steps_per_epoch = int(train_generator.n / batch_size)
validation_steps = int(test_generator.n / batch_size)

model = Models.getVGG16()

 model.fit_generator(
            train_generator,
            steps_per_epoch=steps_per_epoch,
            epochs=nb_epoch,
            validation_data=test_generator,
            validation_steps=validation_steps,
            verbose=1
            )
```
[参考链接](https://github.com/AIChallenger/AI_Challenger_2018/blob/master/Baselines/zero_shot_learning_baseline/train_CNN.py)

# 模型超参数调优
[参考链接](http://www.10tiao.com/html/368/201608/2650781766/3.html)

# 实验结果分析
## 通过t-test检验比较两个模型的性能(如accuracy)是否为同分布
举个栗子，a,b两个list分别为模型A,B在n个测试数据集上的评价指标结果
```
from scipy.stats import ttest_ind
from scipy.stats import levene

print(levene(a, b) #用于确定a,b是否方差为同分布
print("equal_var=True",ttest_ind(a, b, equal_var=True))
print("equal_var=False",ttest_ind(a, b, equal_var=False)) 
```
